# Traffic for London (TfL) Parser:

These parsers analyze data, available from Transport for London (TfL). These data come from the Urban Traffic Control System (UTC), a system used to measure the traffic flow across London to drive the traffic light optimizer system. The data are used to develop a method for the deployment of Road Side Units for a Vehicular Network

# How to use the Parser:

## Parser for the complete detectors folder:

### Scot Parser:

This parser will extract useful data from scoot_detectors.csv. This file contains information about each separate SCOOT detector. In particular, we will extract: longitude, latitude, topographic identifier, easting (cartesian coordinates), northing (cartesian coordinates) and detector id. With this extracted information we can build a database to retrieve in a faster way the location of the detectors.

### Cleaning Parser:

This parser analyze all the data from a month and it will create a folder for each day that contains a file for each junction. The structure of this file is the same of the original file but we'll keep only the detectors that have a "location information" (i.e. they exist in the file generated by scot_parser.py).

### Single Detector Parser:

This parser can be used the select only certain detector. It generates a folder for each main detector (e.g. 01-142) that contains the detailed file for each road detector (e.g. 01-142u and 01-142w)

## Parser for the selected detector folder:
	
These parsers has to be placed inside the directory that contains the following files.

The file of the single day must be in this type of folder: 
<counter>. <Number> Festive Week
<counter>. <Number> Work Week

### Velocity Parser:

To perform automatically all this points you can run the ./velocity.sh script
			
1) First of all you need to run the velocity_parser.py to compute the velocity of the single vehicle
2) Now you can run the velocity_interval_parser.py that computes the mean velocity in a certain time frame
3) Now you can run the mean_velocity.py parser that computes a mean velocity for the work and festive week, using the velocity in the same time frame used in point 2)
4) Now you can run the last script, velocity_plot.py that generates a plot starting from the data computed during point 3) 
			
### Interarrival Parser:

To perform automatically all this points you can run the ./interarrival.sh script
			
1) First of all you need to run the interarrival_time_interval_parser.py parser that computes the interarrival times in a specific time frame
2) Now you can run the mean_interarrival.py parser that computes a mean interarrival time for the work and festive week, using the interarrival time in the same time frame used in point 1)
3) Now you can run the last script, interarrival_plot.py that generates a plot starting from the data computed during point 2)

With the intearrival_maximum_plot.py you can generate the plot of the global maximum interarrival time

### Vehicle Number Parser:

To perform automatically all this points you can run the ./vehicle_number.sh script

1) First of all you need to run the vehicle_numer_interval_parser.py that computes the number of vehicle in a specific time frame
2) Now you can run the mean_vehicle_number.py parser that computes the mean vehicle number for the work and festive week, using the same time frame of point 1)
3) Now you can run the last script that, vehicle_number_plot.py that generates a plot starting from the data computed during point 2)

### Throughput Parser:

For every Access Point deployment there is a specific parser, named throughput_parser_conf<number>.py. This parser computes the throughput of every access point and generates a plot

### Detector Time Parser:
			
This parser computes the time needed to reach a detector from another. The raw data is road_x.csv and inside it there is the placement of each pair of detectors
			
### Maximum Inter-Attival Plot:

This parser plots the maximum inter-arrival time between all the detectors
